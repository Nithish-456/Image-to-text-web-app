# ğŸ–¼ï¸ Image Description Web Application  

## âœ¨ Overview  
This project is a web application that allows users to upload an image and receive a **textual description** of its content using a pre-trained **image captioning model** from Hugging Face.  

The application combines the power of **FastAPI** for the backend and **Gradio** for a sleek, user-friendly interface. ğŸš€  

---

## ğŸ’¡ Approach  

### ğŸ” Model Selection  
We utilized the **BLIP (Bootstrapping Language-Image Pre-training)** model from Salesforce, available on Hugging Face. This state-of-the-art model excels in generating descriptive captions for images.  

### ğŸ› ï¸ Backend Development  
- Built with **FastAPI** for creating a fast and efficient RESTful API.  
- Includes an endpoint to handle image uploads and process them with the BLIP model.  

### ğŸ¨ Frontend Development  
- Developed with **Gradio**, providing an intuitive web interface.  
- Users can upload images, and captions are generated in real-time!  

### ğŸš¢ Deployment  
- Run the application locally or use **Docker** for easy deployment.  
- Step-by-step instructions are provided for both methods.  

---

## âœ¨ Features  

- ğŸ“¤ **Upload images** and get descriptive captions instantly.  
- ğŸ” Powered by a **pre-trained image captioning model** for high accuracy.  
- ğŸŒŸ Simple, intuitive, and user-friendly interface using Gradio.  
- âš¡ Option to run as a REST API with **FastAPI**.  

---

## ğŸ“¦ Installation  

### ğŸ”§ Prerequisites  

- ğŸ Python 3.7 or higher  
- ğŸ“¦ pip (Python package installer)  

### ğŸ› ï¸ Step-by-Step Guide  

1. **Clone the Repository**  
   ```bash  
   git clone <https://github.com/Nithish-456/Image-to-text-web-app.git>  
   cd <image_to_text>  
'''
### Step 2: Create a Virtual Environment (Optional)
### Step 3: Install requierd packages: pip install gradio transformers pillow
### Step 4: Run Frontend
 - python frontend.py
 - Open your web browser and navigate to http://localhost:7860 to access the interface.
### Step 5: Run Backend
 - If you prefer to use FastAPI, you can run the FastAPI application with the following code in backend.py
 - Access the application at http://localhost:8000
